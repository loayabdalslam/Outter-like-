{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-10T06:57:48.702174100Z",
     "start_time": "2024-12-10T06:57:37.084359900Z"
    }
   },
   "outputs": [],
   "source": [
    "from flask import Flask, send_from_directory\n",
    "from flask_cors import CORS\n",
    "import logging\n",
    "from flask_socketio import SocketIO\n",
    "import numpy as np\n",
    "import wave\n",
    "import io\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "import base64\n",
    "import asyncio\n",
    "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\n",
    "import torch\n",
    "import torchaudio\n",
    "from flask import render_template\n",
    "import librosa\n",
    "import csv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "TIMING_CSV = \"processing_times.csv\"\n",
    "if not os.path.exists(TIMING_CSV):\n",
    "    with open(TIMING_CSV, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Timestamp\", \"Chunk Duration (sec)\", \"Processing Time (sec)\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T13:28:22.225808500Z",
     "start_time": "2024-12-10T13:28:22.209747900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 15:30:13,347 - urllib3.connectionpool - DEBUG - Resetting dropped connection: huggingface.co\n",
      "2024-12-10 15:30:14,011 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /MohamedRashad/Arabic-Whisper-CodeSwitching-Edition/resolve/main/processor_config.json HTTP/11\" 404 0\n",
      "2024-12-10 15:30:14,200 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /MohamedRashad/Arabic-Whisper-CodeSwitching-Edition/resolve/main/preprocessor_config.json HTTP/11\" 200 0\n",
      "2024-12-10 15:30:14,376 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /MohamedRashad/Arabic-Whisper-CodeSwitching-Edition/resolve/main/preprocessor_config.json HTTP/11\" 200 0\n",
      "2024-12-10 15:30:14,536 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /MohamedRashad/Arabic-Whisper-CodeSwitching-Edition/resolve/main/preprocessor_config.json HTTP/11\" 200 0\n",
      "2024-12-10 15:30:14,796 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /MohamedRashad/Arabic-Whisper-CodeSwitching-Edition/resolve/main/tokenizer_config.json HTTP/11\" 200 0\n",
      "2024-12-10 15:30:15,648 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /MohamedRashad/Arabic-Whisper-CodeSwitching-Edition/resolve/main/processor_config.json HTTP/11\" 404 0\n",
      "2024-12-10 15:30:15,863 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /MohamedRashad/Arabic-Whisper-CodeSwitching-Edition/resolve/main/chat_template.json HTTP/11\" 404 0\n",
      "2024-12-10 15:30:16,053 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /MohamedRashad/Arabic-Whisper-CodeSwitching-Edition/resolve/main/chat_template.jinja HTTP/11\" 404 0\n",
      "2024-12-10 15:30:16,475 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /MohamedRashad/Arabic-Whisper-CodeSwitching-Edition/resolve/main/config.json HTTP/11\" 200 0\n",
      "2024-12-10 15:33:04,423 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /MohamedRashad/Arabic-Whisper-CodeSwitching-Edition/resolve/main/generation_config.json HTTP/11\" 200 0\n",
      "2024-12-10 15:33:11,764 - asyncio - DEBUG - Using selector: SelectSelector\n"
     ]
    }
   ],
   "source": [
    "# Initialize Hugging Face model\n",
    "processor = AutoProcessor.from_pretrained(\"MohamedRashad/Arabic-Whisper-CodeSwitching-Edition\")\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\"MohamedRashad/Arabic-Whisper-CodeSwitching-Edition\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Add this after app initialization\n",
    "VOICE_DIR = \"voice\"\n",
    "if not os.path.exists(VOICE_DIR):\n",
    "    os.makedirs(VOICE_DIR)\n",
    "\n",
    "\n",
    "class AudioProcessor:\n",
    "    def __init__(self):\n",
    "        self.audio_queue = queue.Queue()\n",
    "        self.processing_thread = None\n",
    "        self.is_running = False\n",
    "        self.voice_dir = VOICE_DIR\n",
    "        self.last_process_time = time.time()\n",
    "        self.buffer = np.array([], dtype=np.float32)\n",
    "        self.loop = asyncio.new_event_loop()\n",
    "\n",
    "    def stop_processing(self):\n",
    "        \"\"\"Stop the audio processing thread\"\"\"\n",
    "        self.is_running = False\n",
    "        if self.processing_thread is not None:\n",
    "            self.processing_thread.join()\n",
    "        if self.loop.is_running():\n",
    "            self.loop.call_soon_threadsafe(self.loop.stop)\n",
    "        logger.info(\"Audio processing thread stopped\")\n",
    "\n",
    "    async def process_with_huggingface(self, audio_file_path: str, chunk_duration: int = None) -> str:\n",
    "        \"\"\"Process audio file with Hugging Face model, log timing.\"\"\"\n",
    "        if not os.path.isfile(audio_file_path):\n",
    "            raise ValueError(f\"Invalid audio file path: {audio_file_path}\")\n",
    "\n",
    "        try:\n",
    "            start_time = time.time()  # Start timing\n",
    "\n",
    "            # Load and process the audio file\n",
    "            audio_data, sample_rate = librosa.load(audio_file_path, sr=None)\n",
    "\n",
    "            # Resample audio data to 16000 Hz if it's not already\n",
    "            if sample_rate != 16000:\n",
    "                logger.info(f\"Resampling audio from {sample_rate} Hz to 16000 Hz\")\n",
    "                audio_data = librosa.resample(audio_data, orig_sr=sample_rate, target_sr=16000)\n",
    "\n",
    "            # Prepare the input for the model\n",
    "            inputs = processor(audio_data, sampling_rate=16000, return_tensors=\"pt\")\n",
    "\n",
    "            # Generate transcription with the model\n",
    "            with torch.no_grad():\n",
    "                generated_ids = model.generate(inputs[\"input_features\"])\n",
    "\n",
    "            # Decode the generated ids to text\n",
    "            transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            result = \" \".join(transcription)\n",
    "\n",
    "            # Measure processing time\n",
    "            end_time = time.time()\n",
    "            processing_time = end_time - start_time\n",
    "\n",
    "            # Log timing to CSV\n",
    "            with open(TIMING_CSV, 'a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([datetime.now().isoformat(), chunk_duration, processing_time])\n",
    "\n",
    "            logger.info(f\"Processing Time: {processing_time:.2f} seconds for duration: {chunk_duration} sec\")\n",
    "            logger.info(f\"Transcription result: {result}\")\n",
    "\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Unexpected error processing audio: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def process_audio_chunk(self, audio_data: np.ndarray, timestamp: int, mode: str):\n",
    "        try:\n",
    "            self.buffer = np.append(self.buffer, audio_data)\n",
    "            chunk_samples = 44100 * 3  # 3 seconds worth of audio at 44.1kHz\n",
    "\n",
    "            while len(self.buffer) >= chunk_samples:\n",
    "                # Extract a chunk of audio data\n",
    "                chunk = self.buffer[:chunk_samples]\n",
    "                self.buffer = self.buffer[chunk_samples:]\n",
    "\n",
    "                logger.info(f\"Processing chunk of {len(chunk)} samples\")\n",
    "\n",
    "                # Save the chunk to a temporary file\n",
    "                timestamp_str = datetime.fromtimestamp(timestamp / 1000).strftime('%Y%m%d_%H%M%S')\n",
    "                filename = f\"{timestamp_str}_{mode}.wav\"\n",
    "                filepath = os.path.join(self.voice_dir, filename)\n",
    "\n",
    "                with wave.open(filepath, 'wb') as wav_file:\n",
    "                    wav_file.setnchannels(1)\n",
    "                    wav_file.setsampwidth(2)\n",
    "                    wav_file.setframerate(44100)\n",
    "                    audio_16bit = (chunk * 32767).astype(np.int16)\n",
    "                    wav_file.writeframes(audio_16bit.tobytes())\n",
    "\n",
    "                logger.info(f\"Saved audio chunk: {filename}\")\n",
    "\n",
    "                # Transcribe the chunk\n",
    "                future = asyncio.run_coroutine_threadsafe(\n",
    "                    self.process_with_huggingface(filepath),\n",
    "                    self.loop\n",
    "                )\n",
    "                transcription = future.result()\n",
    "\n",
    "                # Emit the transcription\n",
    "                if transcription:\n",
    "                    socketio.emit('transcription', {\n",
    "                        'text': transcription,\n",
    "                        'timestamp': timestamp,\n",
    "                        'mode': mode\n",
    "                    })\n",
    "                    logger.info(f\"Chunk Transcription: {transcription}\")\n",
    "\n",
    "            # Update the last process time to throttle processing\n",
    "            self.last_process_time = time.time()\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing audio chunk: {e}\", exc_info=True)\n",
    "            self.buffer = np.array([], dtype=np.float32)\n",
    "\n",
    "\n",
    "# Create audio processor instance\n",
    "audio_processor = AudioProcessor()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T13:33:12.046725500Z",
     "start_time": "2024-12-10T13:30:13.279498Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "socketio = SocketIO(app, cors_allowed_origins=\"*\", ping_timeout=120)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "        logging.FileHandler('audio_server.log')\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Add socket.io logging\n",
    "logging.getLogger('socketio').setLevel(logging.DEBUG)\n",
    "logging.getLogger('engineio').setLevel(logging.DEBUG)\n",
    "\n",
    "@app.route('/voice/<path:filename>')\n",
    "def serve_voice_files(filename):\n",
    "    return send_from_directory('voice', filename)\n",
    "\n",
    "@app.route('/transcribe/<filename>')\n",
    "def transcribe_file(filename):\n",
    "    file_path = os.path.join(VOICE_DIR, filename)\n",
    "    if not os.path.isfile(file_path):\n",
    "        return {\"error\": \"File not found\"}, 404\n",
    "    try:\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "        transcription = loop.run_until_complete(audio_processor.process_with_huggingface(file_path))\n",
    "        loop.close()\n",
    "        return transcription, 200, {'Content-Type': 'text/plain; charset=utf-8'}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in transcription: {e}\", exc_info=True)\n",
    "        return {\"error\": str(e)}, 500\n",
    "\n",
    "\n",
    "@socketio.on('connect')\n",
    "def handle_connect():\n",
    "    \"\"\"Handle client connection\"\"\"\n",
    "    logger.info('Client connected')\n",
    "    if not audio_processor.is_running:\n",
    "        audio_processor.start_processing()\n",
    "\n",
    "@socketio.on('disconnect')\n",
    "def handle_disconnect():\n",
    "    \"\"\"Handle client disconnection\"\"\"\n",
    "    logger.info('Client disconnected')\n",
    "    audio_processor.stop_processing()\n",
    "\n",
    "@socketio.on('audio_data')\n",
    "def handle_audio_data(data):\n",
    "    \"\"\"Handle incoming audio data\"\"\"\n",
    "    try:\n",
    "        audio_array = np.frombuffer(data['buffer'], dtype=np.float32)\n",
    "        timestamp = data.get('timestamp', int(time.time() * 1000))\n",
    "        mode = data.get('mode', 'both')\n",
    "\n",
    "        if len(audio_array) > 0:\n",
    "            logger.debug(f\"Received audio chunk - Length: {len(audio_array)}, Mode: {mode}\")\n",
    "            audio_processor.process_audio_chunk(audio_array, timestamp, mode)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error handling audio data: {e}\", exc_info=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T13:48:21.563036500Z",
     "start_time": "2024-12-10T13:48:21.454252Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 15:48:25,108 - werkzeug - WARNING - Werkzeug appears to be used in a production deployment. Consider switching to a production web server instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 15:48:26,702 - werkzeug - INFO - \u001B[31m\u001B[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001B[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://10.24.18.6:5000\n",
      "2024-12-10 15:48:26,704 - werkzeug - INFO - \u001B[33mPress CTRL+C to quit\u001B[0m\n",
      "2024-12-10 15:49:46,797 - asyncio - DEBUG - Using selector: SelectSelector\n",
      "2024-12-10 15:49:47,781 - __main__ - INFO - Resampling audio from 48000 Hz to 16000 Hz\n",
      "2024-12-10 15:50:42,058 - __main__ - INFO - Processing Time: 55.02 seconds for duration: None sec\n",
      "2024-12-10 15:50:42,061 - __main__ - INFO - Transcription result: مسائل full على مدريد والمدريد هو الأصدقاء والمتابعين المفضلين ل podcast المحلقين، اليوم معنا محمد يسري المدريدي العتيد، أنت عارف أنك أول سكاندرونيجي ل podcast؟\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\omar.mounir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\logging\\__init__.py\", line 1086, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"C:\\Users\\omar.mounir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "UnicodeEncodeError: 'charmap' codec can't encode characters in position 66-70: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"C:\\Users\\omar.mounir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py\", line 937, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\omar.mounir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"E:\\Projects\\Other Projects\\Otter\\Outter-like-\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"C:\\Users\\omar.mounir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\omar.mounir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\socketserver.py\", line 683, in process_request_thread\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"C:\\Users\\omar.mounir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"C:\\Users\\omar.mounir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"E:\\Projects\\Other Projects\\Otter\\Outter-like-\\venv\\lib\\site-packages\\werkzeug\\serving.py\", line 398, in handle\n",
      "    super().handle()\n",
      "  File \"C:\\Users\\omar.mounir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\server.py\", line 425, in handle\n",
      "    self.handle_one_request()\n",
      "  File \"C:\\Users\\omar.mounir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\server.py\", line 413, in handle_one_request\n",
      "    method()\n",
      "  File \"E:\\Projects\\Other Projects\\Otter\\Outter-like-\\venv\\lib\\site-packages\\werkzeug\\serving.py\", line 370, in run_wsgi\n",
      "    execute(self.server.app)\n",
      "  File \"E:\\Projects\\Other Projects\\Otter\\Outter-like-\\venv\\lib\\site-packages\\werkzeug\\serving.py\", line 333, in execute\n",
      "    for data in application_iter:\n",
      "  File \"E:\\Projects\\Other Projects\\Otter\\Outter-like-\\venv\\lib\\site-packages\\werkzeug\\debug\\__init__.py\", line 343, in debug_application\n",
      "    app_iter = self.app(environ, start_response)\n",
      "  File \"E:\\Projects\\Other Projects\\Otter\\Outter-like-\\venv\\lib\\site-packages\\flask\\app.py\", line 1536, in __call__\n",
      "    return self.wsgi_app(environ, start_response)\n",
      "  File \"E:\\Projects\\Other Projects\\Otter\\Outter-like-\\venv\\lib\\site-packages\\flask_socketio\\__init__.py\", line 43, in __call__\n",
      "    return super(_SocketIOMiddleware, self).__call__(environ,\n",
      "  File \"E:\\Projects\\Other Projects\\Otter\\Outter-like-\\venv\\lib\\site-packages\\engineio\\middleware.py\", line 74, in __call__\n",
      "    return self.wsgi_app(environ, start_response)\n",
      "  File \"E:\\Projects\\Other Projects\\Otter\\Outter-like-\\venv\\lib\\site-packages\\flask\\app.py\", line 1511, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"E:\\Projects\\Other Projects\\Otter\\Outter-like-\\venv\\lib\\site-packages\\flask\\app.py\", line 917, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"E:\\Projects\\Other Projects\\Otter\\Outter-like-\\venv\\lib\\site-packages\\flask\\app.py\", line 902, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "  File \"C:\\Users\\omar.mounir\\AppData\\Local\\Temp\\ipykernel_3028\\1448880911.py\", line 32, in transcribe_file\n",
      "    transcription = loop.run_until_complete(audio_processor.process_with_huggingface(file_path))\n",
      "  File \"C:\\Users\\omar.mounir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 634, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"C:\\Users\\omar.mounir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\omar.mounir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\omar.mounir\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\omar.mounir\\AppData\\Local\\Temp\\ipykernel_3028\\3509460250.py\", line 69, in process_with_huggingface\n",
      "    logger.info(f\"Transcription result: {result}\")\n",
      "Message: 'Transcription result: مسائل full على مدريد والمدريد هو الأصدقاء والمتابعين المفضلين ل podcast المحلقين، اليوم معنا محمد يسري المدريدي العتيد، أنت عارف أنك أول سكاندرونيجي ل podcast؟'\n",
      "Arguments: ()\n",
      "2024-12-10 15:50:42,641 - werkzeug - INFO - 127.0.0.1 - - [10/Dec/2024 15:50:42] \"GET /transcribe/record0.wav HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        socketio.run(app, host='0.0.0.0', port=5000, debug=True, use_reloader=False, allow_unsafe_werkzeug=True)\n",
    "    finally:\n",
    "        audio_processor.stop_processing()\n",
    "        print('Processing is done')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-12-10T13:48:24.846011500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
